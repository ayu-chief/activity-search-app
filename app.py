# app.py
import time
import re
import unicodedata
from typing import List, Dict

import streamlit as st
import pandas as pd
import gspread
from gspread.exceptions import APIError
from google.oauth2.service_account import Credentials

# æ¤œç´¢ç³»
from sentence_transformers import SentenceTransformer, util
from rank_bm25 import BM25Okapi

# -----------------------------------------------------------------------------
# åŸºæœ¬è¨­å®š
# -----------------------------------------------------------------------------
st.set_page_config(page_title="ğŸ¯ æ´»å‹•ã‚³ãƒ³ãƒ†ãƒ³ãƒ„æ¤œç´¢", layout="wide")

# -----------------------------------------------------------------------------
# Google Sheets æ¥ç¶š
# -----------------------------------------------------------------------------
SERVICE_ACCOUNT_INFO = st.secrets["google_service_account"]  # Secretsã«å…¥ã‚ŒãŸJSON
SPREADSHEET_IDS = [
    "1GCenO3IlDFrSITj1r90G_Vz_11D66POc8ny9HMtdCcM",
    "1Rjkgc6whTpg4FKUNLVSdzFSya-_tg42Wg4e10p-MmmI",
    "1PFDBuFuqxC4OWMCPjErP8uYYRovE55t-0oWsXNMCMqc",
    "1p4utUR9of_uSQNpzwJpSXgKiPrNur5nSTgHZvrbwmuc",
    "1HULvSdUAdSNdXXhPshu4mfwraf-bNq6zakFRhKF4Yfg",
]
SCOPES = [
    "https://www.googleapis.com/auth/spreadsheets",
    "https://www.googleapis.com/auth/drive",
]
creds = Credentials.from_service_account_info(SERVICE_ACCOUNT_INFO, scopes=SCOPES)
gc = gspread.authorize(creds)
st.info(f"Service Account: {creds.service_account_email}")

# ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾ç­–ç”¨
BASE_WAIT = 1.1   # ã‚·ãƒ¼ãƒˆé–“ã®æœ€å°å¾…æ©Ÿï¼ˆç§’ï¼‰
MAX_RETRY = 5     # 429æ™‚ã®æœ€å¤§ãƒªãƒˆãƒ©ã‚¤å›æ•°


# -----------------------------------------------------------------------------
# æ­£è¦åŒ–ãƒ˜ãƒ«ãƒ‘
# -----------------------------------------------------------------------------
def normalize(s: str) -> str:
    if s is None:
        return ""
    s = unicodedata.normalize("NFKC", str(s))
    s = re.sub(r"\s+", " ", s).strip()
    return s


# -----------------------------------------------------------------------------
# ã‚·ãƒ¼ãƒˆ1æš â†’ ãƒ¬ã‚³ãƒ¼ãƒ‰åŒ–ï¼ˆãƒ©ãƒ™ãƒ«å–ã‚Šå‡ºã—ï¼‰
# -----------------------------------------------------------------------------
LABELS = [
    "æ ¡èˆå", "ã‚³ãƒ³ãƒ†ãƒ³ãƒ„å", "ãƒ†ãƒ¼ãƒ", "å¯¾è±¡ç”Ÿå¾’", "å¯¾è±¡", "å‚åŠ äººæ•°",
    "æº–å‚™ç‰©", "å®Ÿæ–½æ–¹æ³•", "å­ä¾›ãŸã¡ã®åå¿œ", "å­ã©ã‚‚ãŸã¡ã®åå¿œ", "è‰¯ã‹ã£ãŸç‚¹", "æ”¹å–„ç‚¹",
]

def extract_value(values: List[List[str]], label: str) -> str:
    lab = normalize(label)
    for row in values:
        for j, cell in enumerate(row):
            if lab and lab in normalize(cell):
                right = row[j+1:] if j+1 < len(row) else []
                toks = [c for c in right if str(c).strip()]
                if toks:
                    return " ".join(normalize(c) for c in toks).strip()
    return ""

def parse_sheet(values: List[List[str]]) -> Dict[str, str]:
    rec = {}
    for lab in LABELS:
        rec[lab] = extract_value(values, lab)

    # å­ã©ã‚‚/å­ä¾› ã‚’çµ±ä¸€
    if not rec.get("å­ä¾›ãŸã¡ã®åå¿œ"):
        rec["å­ä¾›ãŸã¡ã®åå¿œ"] = rec.get("å­ã©ã‚‚ãŸã¡ã®åå¿œ", "")

    out = {
        "æ ¡èˆå": rec.get("æ ¡èˆå", ""),
        "ã‚³ãƒ³ãƒ†ãƒ³ãƒ„å": rec.get("ã‚³ãƒ³ãƒ†ãƒ³ãƒ„å", ""),
        "ãƒ†ãƒ¼ãƒ": rec.get("ãƒ†ãƒ¼ãƒ", ""),
        "å¯¾è±¡": rec.get("å¯¾è±¡ç”Ÿå¾’", "") or rec.get("å¯¾è±¡", ""),
        "å‚åŠ äººæ•°": rec.get("å‚åŠ äººæ•°", ""),
        "æº–å‚™ç‰©": rec.get("æº–å‚™ç‰©", ""),
        "å®Ÿæ–½æ–¹æ³•": rec.get("å®Ÿæ–½æ–¹æ³•", ""),
        "å­ä¾›ãŸã¡ã®åå¿œ": rec.get("å­ä¾›ãŸã¡ã®åå¿œ", ""),
        "è‰¯ã‹ã£ãŸç‚¹": rec.get("è‰¯ã‹ã£ãŸç‚¹", ""),
        "æ”¹å–„ç‚¹": rec.get("æ”¹å–„ç‚¹", ""),
    }

    # ä¸»è¦ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒç©ºãªã‚‰ä¿é™ºã¨ã—ã¦å…¨ã‚»ãƒ«é€£çµ
    if not any(out.values()):
        flat = " ".join([" ".join([str(c) for c in r if str(c).strip()]) for r in values])
        out["ã‚³ãƒ³ãƒ†ãƒ³ãƒ„å"] = out["ã‚³ãƒ³ãƒ†ãƒ³ãƒ„å"] or "(åç§°æœªè¨­å®š)"
        out["ãƒ†ãƒ¼ãƒ"] = flat[:200]

    return out


# -----------------------------------------------------------------------------
# 429ã‚’é¿ã‘ã‚‹ï¼šã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆå˜ä½ã§ batchGet ã™ã‚‹ãƒ­ãƒ¼ãƒ€
# -----------------------------------------------------------------------------
def open_sheet_by_id(sid: str):
    for attempt in range(MAX_RETRY):
        try:
            sh = gc.open_by_key(sid)
            st.success(f"âœ… Opened: {sh.title} ({sid})")
            return sh
        except APIError as e:
            code = getattr(getattr(e, "response", None), "status_code", None)
            if code == 429 and attempt < MAX_RETRY - 1:
                wait = BASE_WAIT * (2 ** attempt)
                st.warning(f"â³ Rate limit: open_by_key (retry {attempt+1}/{MAX_RETRY}) in {wait:.1f}s")
                time.sleep(wait)
                continue
            st.error(f"âŒ Failed to open (status={code}): {sid}")
            st.code(getattr(getattr(e, "response", None), "text", str(e))[:2000])
            return None
        except Exception as e:
            st.error(f"âŒ Failed to open (unexpected): {sid}")
            st.code(str(e))
            return None

@st.cache_data(show_spinner=True, ttl=6*60*60)  # 6æ™‚é–“ã‚­ãƒ£ãƒƒã‚·ãƒ¥
def load_all_data() -> pd.DataFrame:
    """
    å„ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã«ã¤ã„ã¦ values.batchGet ã§å…¨ãƒ¯ãƒ¼ã‚¯ã‚·ãƒ¼ãƒˆã‚’ä¸€æ‹¬å–å¾—ã€‚
    ï¼ ãƒªã‚¯ã‚¨ã‚¹ãƒˆå›æ•°ã‚’ã€Œã‚·ãƒ¼ãƒˆæ•°ã€â†’ã€Œã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆæ•°ã€ã«åœ§ç¸®ã€‚
    """
    rows = []
    for sid in SPREADSHEET_IDS:
        sh = open_sheet_by_id(sid)
        if not sh:
            continue

        # ä½¿ã†åˆ—å¹…ã‚’å¿…è¦ã«å¿œã˜ã¦ç‹­ã‚ã‚‹ï¼ˆA:Q ãªã©ï¼‰
        ranges = [f"'{ws.title}'!A:Z" for ws in sh.worksheets()]

        time.sleep(BASE_WAIT)  # ã‚·ãƒ¼ãƒˆé–“ã®é–“éš”

        vals_resp = None
        for attempt in range(MAX_RETRY):
            try:
                vals_resp = sh.values_batch_get(
                    ranges=ranges,
                    params={"majorDimension": "ROWS"}
                )
                break
            except APIError as e:
                code = getattr(getattr(e, "response", None), "status_code", None)
                if code == 429 and attempt < MAX_RETRY - 1:
                    wait = BASE_WAIT * (2 ** attempt)
                    st.warning(f"â³ Rate limit: values.batchGet (retry {attempt+1}/{MAX_RETRY}) in {wait:.1f}s")
                    time.sleep(wait)
                    continue
                st.error(f"âŒ Failed batchGet (status={code}): {sh.title}")
                st.code(getattr(getattr(e, "response", None), "text", str(e))[:2000])
                vals_resp = None
                break
            except Exception as e:
                st.error(f"âŒ Failed batchGet (unexpected): {sh.title}")
                st.code(str(e))
                vals_resp = None
                break

        if not vals_resp:
            continue

        for vr in vals_resp.get("valueRanges", []):
            rng = vr.get("range", "")
            ws_title = rng.split("!")[0].strip("'")
            vals = vr.get("values", [])
            if not vals:
                continue

            rec = parse_sheet(vals)
            if not any(rec.values()):
                continue

            rec["ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆ"] = sh.title
            rec["ãƒ•ã‚¡ã‚¤ãƒ«ID"] = sid
            rec["ã‚·ãƒ¼ãƒˆå"] = ws_title
            rec["æ¤œç´¢ç”¨ãƒ†ã‚­ã‚¹ãƒˆ"] = " ".join([
                rec.get("ã‚³ãƒ³ãƒ†ãƒ³ãƒ„å",""), rec.get("ãƒ†ãƒ¼ãƒ",""), rec.get("å¯¾è±¡",""),
                rec.get("æº–å‚™ç‰©",""), rec.get("å®Ÿæ–½æ–¹æ³•",""),
                rec.get("å­ä¾›ãŸã¡ã®åå¿œ",""), rec.get("è‰¯ã‹ã£ãŸç‚¹",""), rec.get("æ”¹å–„ç‚¹","")
            ]).strip()
            rows.append(rec)

    df = pd.DataFrame(rows)
    return df


# -----------------------------------------------------------------------------
# æ¤œç´¢æº–å‚™ï¼ˆåŸ‹ã‚è¾¼ã¿ï¼‹BM25ï¼‰
# -----------------------------------------------------------------------------
@st.cache_resource(show_spinner=True)
def load_embedder():
    # å°å‹ãƒ»å¤šè¨€èª
    return SentenceTransformer("paraphrase-multilingual-MiniLM-L12-v2")

@st.cache_data(show_spinner=False)
def build_bm25(corpus_tokens: List[List[str]]):
    return BM25Okapi(corpus_tokens)

def tokenize_ja(text: str) -> List[str]:
    # ã‚·ãƒ³ãƒ—ãƒ«ãªç©ºç™½ãƒ»å¥èª­ç‚¹åˆ†å‰²ï¼ˆå½¢æ…‹ç´ è§£æãªã—ã§ã‚‚ãã“ãã“å‹•ãï¼‰
    text = normalize(text)
    toks = re.split(r"[ \u3000ã€ã€‚ãƒ»,./!?ï¼ï¼Ÿ\-\n\r\t]+", text)
    return [t for t in toks if t]

SYNONYMS = {
    "ç™ºè¡¨": ["ãƒ—ãƒ¬ã‚¼ãƒ³", "ã‚¹ãƒ”ãƒ¼ãƒ", "è¡¨ç¾", "ç™ºè¡¨ç·´ç¿’"],
    "è¡¨ç¾": ["ç™ºè¡¨", "ä¼ãˆã‚‹", "ã‚¢ã‚¦ãƒˆãƒ—ãƒƒãƒˆ"],
    "å”åŠ›": ["å”åƒ", "ãƒãƒ¼ãƒ ", "ã‚°ãƒ«ãƒ¼ãƒ—", "å…±åŒ"],
    "å‰µä½œ": ["ã‚‚ã®ã¥ãã‚Š", "åˆ¶ä½œ", "å·¥ä½œ", "ã‚¯ãƒªã‚¨ã‚¤ãƒ†ã‚£ãƒ–"],
    "èª­è§£": ["èª­ã¿å–ã‚Š", "æ„Ÿæƒ³", "èª­æ›¸", "æœ—èª­"],
}


# -----------------------------------------------------------------------------
# UI
# -----------------------------------------------------------------------------
st.title("ğŸ¯ æ´»å‹•ã‚³ãƒ³ãƒ†ãƒ³ãƒ„æ¤œç´¢")

with st.sidebar:
    st.header("æ¤œç´¢è¨­å®š")
    alpha = st.slider("æ„å‘³é‡è¦–ï¼ˆ1.0ï¼‰ â†â†’ èªä¸€è‡´é‡è¦–ï¼ˆ0.0ï¼‰", min_value=0.0, max_value=1.0, value=0.7, step=0.05)
    top_k = st.slider("ä»¶æ•°", 5, 50, 15)
    st.caption("â€»åˆå›ã¯èª­ã¿è¾¼ã¿ã«æ™‚é–“ãŒã‹ã‹ã‚Šã¾ã™ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥å¾Œã¯é€Ÿããªã‚Šã¾ã™ï¼‰")

# ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
with st.spinner("ã‚·ãƒ¼ãƒˆã‚’èª­ã¿è¾¼ã‚“ã§ã„ã¾ã™â€¦"):
    df = load_all_data()

st.write(f"ğŸ“„ èª­ã¿è¾¼ã‚ãŸãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {len(df)}")

if len(df) == 0:
    st.stop()

# æ¤œç´¢ã‚³ãƒ¼ãƒ‘ã‚¹æº–å‚™
corpus_texts = (df["æ¤œç´¢ç”¨ãƒ†ã‚­ã‚¹ãƒˆ"].fillna("") + " " + df["ã‚³ãƒ³ãƒ†ãƒ³ãƒ„å"].fillna("")).tolist()
corpus_tokens = [tokenize_ja(t) for t in corpus_texts]
bm25 = build_bm25(corpus_tokens)
embedder = load_embedder()
corpus_emb = embedder.encode(corpus_texts, normalize_embeddings=True, show_progress_bar=False)

# æ¤œç´¢ãƒ•ã‚©ãƒ¼ãƒ 
q = st.text_input("ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›ï¼ˆä¾‹ï¼šç™ºè¡¨ç·´ç¿’ / ã‚°ãƒ«ãƒ¼ãƒ—æ´»å‹• / è¡¨ç¾åŠ› ãªã©ï¼‰", "")
if q:
    # åŒç¾©èªå±•é–‹
    expanded = [q]
    for k, vs in SYNONYMS.items():
        if k in q:
            expanded += vs
    q_expanded = " ".join(expanded)

    # BM25
    q_toks = tokenize_ja(q_expanded)
    bm25_scores = bm25.get_scores(q_toks)

    # åŸ‹ã‚è¾¼ã¿é¡ä¼¼
    q_emb = embedder.encode([q_expanded], normalize_embeddings=True, show_progress_bar=False)
    sem_scores = util.cos_sim(q_emb, corpus_emb).cpu().numpy()[0]

    # æ­£è¦åŒ–ï¼ˆ0-1ï¼‰
    import numpy as np
    def minmax(x):
        x = np.array(x, dtype=float)
        if x.max() - x.min() < 1e-9:
            return np.zeros_like(x)
        return (x - x.min()) / (x.max() - x.min())

    bm25_n = minmax(bm25_scores)
    sem_n = minmax(sem_scores)

    # èåˆ
    final = alpha * sem_n + (1 - alpha) * bm25_n
    idx = np.argsort(final)[::-1][:top_k]

    st.subheader("æ¤œç´¢çµæœ")
    for rank, i in enumerate(idx, start=1):
        row = df.iloc[i]
        url = f"https://docs.google.com/spreadsheets/d/{row['ãƒ•ã‚¡ã‚¤ãƒ«ID']}/edit"
        with st.container(border=True):
            st.markdown(f"**{rank}. {row.get('ã‚³ãƒ³ãƒ†ãƒ³ãƒ„å','(åç§°æœªè¨­å®š)')}** ã€€[{row['ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆ']} / {row['ã‚·ãƒ¼ãƒˆå']}]({url})")
            cols = st.columns(3)
            with cols[0]:
                st.write("**ãƒ†ãƒ¼ãƒ**:", row.get("ãƒ†ãƒ¼ãƒ",""))
                st.write("**å¯¾è±¡**:", row.get("å¯¾è±¡",""))
                st.write("**å‚åŠ äººæ•°**:", row.get("å‚åŠ äººæ•°",""))
            with cols[1]:
                st.write("**æº–å‚™ç‰©**:", row.get("æº–å‚™ç‰©",""))
                st.write("**å®Ÿæ–½æ–¹æ³•**:", row.get("å®Ÿæ–½æ–¹æ³•",""))
            with cols[2]:
                st.write("**å­ä¾›ãŸã¡ã®åå¿œ**:", row.get("å­ä¾›ãŸã¡ã®åå¿œ",""))
                st.write("**è‰¯ã‹ã£ãŸç‚¹**:", row.get("è‰¯ã‹ã£ãŸç‚¹",""))
                st.write("**æ”¹å–„ç‚¹**:", row.get("æ”¹å–„ç‚¹",""))
            st.caption(f"score={final[i]:.3f} / semantic={sem_n[i]:.3f} / bm25={bm25_n[i]:.3f}")

else:
    st.info("æ¤œç´¢èªã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚ä¾‹ï¼š**ç™ºè¡¨ç·´ç¿’**, **ã‚°ãƒ«ãƒ¼ãƒ—æ´»å‹•**, **æœ—èª­**, **å·¥ä½œ**, **è¡¨ç¾åŠ›** ãªã©")
